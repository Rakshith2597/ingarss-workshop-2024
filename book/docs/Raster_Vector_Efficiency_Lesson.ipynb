{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6e8d86e-397f-4127-adab-d585dae98e6e",
   "metadata": {},
   "source": [
    "# Efficiently Selecting and Processing Raster and Vector Data\n",
    "\n",
    "This workflow introduces how to search for, acquire and process raster data efficiently. Specfically, we demonstrate finding [Sentinel-2](https://www.esa.int/Applications/Observing_the_Earth/Copernicus/Sentinel-2) satellite imagery relevant for an area and time, in this case, a time range of a few months in 2022 over a subdistrict in India.\n",
    "\n",
    "Note: some portions of this notebook are inspired by the [Introduction to Geospatial Raster and Vector Data with Python course](https://carpentries-incubator.github.io/geospatial-python/index.html).\n",
    "\n",
    "\n",
    "## Main Objectives\n",
    "\n",
    "- **Access Sentinel-2 data**: Locate and retrieve relevant Sentinel-2 data for a specific area and timeframe via STAC.\n",
    "- **Inspect and visualize raster data**: Examine metadata, including projections, bands, dimensions, no data pixels. Plot raster data correctly.\n",
    "- **Process multi-spectral raster data**: Work with vector data to establish bounds, manage coordinate systems, and set up the area of interest (AOI).\n",
    "- **Interpret time-series raster data**: Learn to explore the time dimension for raster data and search for temporal patterns.\n",
    "- **Cloud and nodata masking**: Handle clouds and no data pixels.\n",
    "- **Compositing**: Create composites from multiple image scenes.\n",
    "- **Speed up raster processing with Dask**: Learn how to optimize raster processing steps using a parallel processing library.\n",
    "- **Raster band math**: Calculate relevant spectral indices using Sentinel-2 data.\n",
    "- **Scalably visualize vector data with Lonboard**: Load a field boundaries with 10000 polygons and visualize it with Lonboard.\n",
    "- **Calculate zonal statistics with the field boundaries**: Show how to calculate zonal statistics for a spectral index.\n",
    "\n",
    "\n",
    "At the end, you'll be able to efficiently process raster imagery for a region and time of interest!\n",
    "\n",
    "Let's begin by importing our necessary packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426b4f7-3f69-40ca-aeba-dd4fe0b0855b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "import geopandas as gpd\n",
    "import odc.stac\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "import pystac_client\n",
    "import rasterio\n",
    "import requests\n",
    "import rioxarray\n",
    "import time\n",
    "import xarray as xr\n",
    "from geopandas import GeoSeries, GeoDataFrame\n",
    "from lonboard import Map, PolygonLayer, viz\n",
    "from pyproj import CRS\n",
    "from rasterstats import zonal_stats\n",
    "from shapely.geometry import box, Point, shape\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4054c9d-c6f0-45fd-b420-3b2a54df7506",
   "metadata": {},
   "source": [
    "## Accessing raster data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4947c3-86d0-4dd3-a91b-a417376deee6",
   "metadata": {},
   "source": [
    "We'll select an area of interest by randomly sampling a subdistrict within India. This is what we will use to obtain geographic bounds required for selecting and acquiring raster data. \n",
    "\n",
    "Note that we set the coordinate reference system (CRS) to the projection that is used to load web map tiles and store coordinate metadata in the STAC catalog, `EPSG:4326 (WGS 84)`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177f8770-9342-4ef7-9c52-3181bccfbf5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the subdistricts boundaries dataset\n",
    "subdistricts = gpd.read_file(\"./KA_subdistrict/KA_subdistrict.shp\")\n",
    "# Shuffle the dataset items\n",
    "subdistricts.sample(frac=1)\n",
    "#subdistrict = subdistricts[subdistricts[\"subdistric\"] == \"Bangalore-South\"]  # UID = 97\n",
    "# Select the first subdistrict\n",
    "subdistrict = subdistricts.head(1).to_crs(\"EPSG:4326\")\n",
    "subdistrict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53a212f-6d04-444b-bdea-a001c42ed46c",
   "metadata": {},
   "source": [
    "Obtain a bounding box for the sampled subdistrict. This is for the image search query we will execute shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10e6040-d964-4e28-9b29-079bcf6cc36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox_coords = subdistrict.total_bounds \n",
    "bounding_box = box(*bbox_coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d2887a-54a5-4a72-a0ba-3b22a423e96f",
   "metadata": {},
   "source": [
    "The area of interest can be seen in the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc575a3b-c9da-4454-9d74-a0d83c00a1fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(subdistrict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1442d0-eebf-4fc2-b0a0-fdaec390d799",
   "metadata": {},
   "source": [
    "Let’s dive into how to search for and retrieve raster data.\n",
    "\n",
    "The [SpatioTemporal Asset Catalog (STAC)](https://stacspec.org/en) is an open standard created to standardize the organization and description of geospatial assets. It has come to serve a crucial role in the geospatial industry by providing a consistent framework and terminology for indexing and accessing Earth observation data along with relevant metadata. This specification allows for streamlined searching, browsing, and retrieval of geospatial information.\n",
    "\n",
    "You can explore geospatial datasets using tools like the [STAC browser](https://radiantearth.github.io/stac-browser/#/?.language=en), which provides an up-to-date interface for navigating STAC catalogs. For instance, the [\"Earth Search\" catalog](https://radiantearth.github.io/stac-browser/#/external/earth-search.aws.element84.com/v1/?.language=en), which includes Sentinel-2 imagery [hosted on AWS](https://registry.opendata.aws/sentinel-2-l2a-cogs/), is a great starting point. \n",
    "\n",
    "To retrieve data from a catalog, locate its API URL in the STAC Browser by clicking the \"Source\" button in the top-right corner. This URL serves as a gateway to access and interact with the catalog's data. For the Earth Search catalog, the API URL would be displayed in this section, enabling you to programmatically access the archive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438c2f58-dcb2-40d4-8a5b-710de636654c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access AWS STAC for Sentinel-2 Data\n",
    "aws_stac_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "\n",
    "# You can query a STAC API endpoint from Python using the pystac_client library:\n",
    "stac_client = pystac_client.Client.open(aws_stac_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1634689-4512-45cf-af8e-e23b329d442b",
   "metadata": {},
   "source": [
    "In the upcoming steps, we will retrieve imagery from the Sentinel-2 L2A collection, which consists of data products processed to Level 2A. This processing level provides bottom-of-atmosphere (BOA) reflectance, making the data ready for analysis without additional atmospheric correction. \n",
    "\n",
    "The data is stored in the **Cloud Optimized GeoTIFF (COG)** format, a type of GeoTIFF specifically designed for efficient access in cloud environments. Unlike traditional GeoTIFFs, COGs are structured with internal data blocks that enable partial retrieval via HTTP requests, eliminating the need to download the entire file. Furthermore, they often include **overviews**, which are lower-resolution versions of the image. These overviews allow users to quickly access less detailed images when high resolution isn’t required, optimizing data transfer and reducing load times for online applications. For more about COGs, visit the [Cloud Optimized GeoTIFF website](http://cogeo.org/).\n",
    "\n",
    "We parameterize our search for available Sentinel-2 scenes in the `sentinel-2-l2a` collection that meet the following criteria:\n",
    "- intersect with a provided bounding box (boundaries of the area of interest);\n",
    "- were captured between January 1, 2022, and December 31, 2022;\n",
    "- have less than 5% cloud cover;\n",
    "- have less than 5% invalid pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e41d70-e3fd-4839-b344-f5c3f9db41d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_search = stac_client.search(\n",
    "    collections=[\"sentinel-2-l2a\"], # Sentinel-2, Level 2A, Cloud Optimized GeoTiffs (COGs)\n",
    "    bbox=list(bbox_coords),\n",
    "    datetime=\"2022-01-01/2022-12-31\",\n",
    "    query={\"eo:cloud_cover\": {\"lt\": 5}, \"s2:nodata_pixel_percentage\": {\"lt\": 5}}, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5e82a2-4c2f-4d91-8448-4c5de9710919",
   "metadata": {},
   "source": [
    "At this point, only metadata has been retrieved, meaning the actual image data has not yet been loaded into memory. However, it’s important to note that metadata alone can occupy significant memory, especially when the search criteria match a large number of images. To handle this efficiently, you can limit the number of search results by using the parameter `limit=n`, where `n` specifies the maximum number of items to return."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874e68c0-6e51-417b-99bd-0b219b5ff8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve all items (still just metadata) from search results\n",
    "s2_items = s2_search.item_collection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f941727-b303-484c-afe4-94926ffed785",
   "metadata": {},
   "source": [
    "After running the query to identify image scenes that match our search criteria, we can check the total number of matches using the `.matched()` method. Keep in mind that this number may change over time as new data continues to be added to the catalog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed92fc4-4ffc-4201-bfa4-12437ea789ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s2_search.matched())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72c06cb0-ff73-4619-9152-b49169d7d8c8",
   "metadata": {},
   "source": [
    "Which should equate to the number of items collected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dd6bfd-4072-414c-909c-00c89ce72ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(s2_items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed4f408-7d24-41a7-abb6-95d05a6fb2bf",
   "metadata": {},
   "source": [
    "Each item corresponds to a single image scene, with metadata that includes details such as the scene's spatial geometry and the time it was captured. These details are accessible through the item's properties.\n",
    "\n",
    "\n",
    "We can see an example for the first item in the search results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1612422-c1b0-4634-b9c8-f29817c6dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "item = s2_items[0]\n",
    "print(item.datetime)\n",
    "print(item.geometry)\n",
    "print(item.properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243564fb-be39-4d32-b5d0-5915949ee63f",
   "metadata": {},
   "source": [
    "As noted earlier, only the metadata has been retrieved so far. Next, we will access the raster data, which consists of the image pixels for the selected scenes. In STAC terminology, these image files are referred to as \"assets,\" with each band of an image represented by a separate asset. A straightforward way to load this image data is by using the URLs provided in the assets attribute of the corresponding item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1c1eea-5677-4a44-b187-d2a9b23bb953",
   "metadata": {},
   "outputs": [],
   "source": [
    "assets = s2_items[0].assets  # first item's asset dictionary\n",
    "print(assets.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbda70f8-653f-469e-b71a-c98cc28bf295",
   "metadata": {},
   "source": [
    "We can see a description of the available assets for the respective sensor/instrument like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb61477-d5bd-403d-a4e8-2b7c447f6a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, asset in assets.items():\n",
    "    print(f\"{key}: {asset.title}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf3608f-1531-4747-a3eb-befba7864fd2",
   "metadata": {},
   "source": [
    "The Sentinel-2 Level-2A data product offers a variety of assets, including raster files for each optical band captured by the multispectral instrument, a true-color thumbnail image (\"visual\"), metadata about the instrument, and scene classification layers (\"SCL\"). Let's retrieve the URLs associated with these assets to access the respective data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11c0b601-5d8c-4add-a35a-132a53761719",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assets[\"thumbnail\"].href)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d5df0f-9c5b-4211-89b0-18e872b49d98",
   "metadata": {},
   "source": [
    "The URL points to the image's location in cloud storage. Since the raster data is stored remotely, we can utilize a library that enables direct access to the image without needing to download it to the local file system beforehand. This library is called `rioxarray`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fdc8aa3-406f-408a-9c94-51d8107c8fa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_href = assets[\"nir\"].href\n",
    "nir = rioxarray.open_rasterio(nir_href)\n",
    "print(nir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fd3462e-ec46-418e-9643-048592ecb1b3",
   "metadata": {},
   "source": [
    "Optionally, we can then save the raster data to a file on disk if needed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935748f0-7338-4aba-a9e9-a64b9632e38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save whole image to disk\n",
    "#nir.rio.to_raster(\"nir.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd9a818-7cae-4bc7-9a9a-60407d3eada8",
   "metadata": {},
   "source": [
    "Working with large rasters, such as the 10-meter NIR band containing over 100 million pixels, can be computationally intensive. To optimize processing, it's often practical to focus on a smaller subset of the data. With the Cloud Optimized GeoTIFF (COG) format, we can efficiently download just the required section instead of the entire file. Before doing so, let's examine the internal tile size of this band in the COG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b4a164-b9ef-453c-8beb-f93a926d3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nir.shape)\n",
    "tile_size = nir.rio._manager.acquire().block_shapes\n",
    "tile_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af56d4b8-601c-44eb-b8c0-2818cf207cfa",
   "metadata": {},
   "source": [
    "In this case, we specify that we want to download the first band in the TIFF file and extract a subset by slicing the width and height dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace65da1-658e-4d16-b7c5-62529f456321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save portion of an image to disk\n",
    "#nir[0,1024:2048,1024:2048].rio.to_raster(\"nir_subset.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6423fb-9669-4db3-9747-75fbf578faf8",
   "metadata": {},
   "source": [
    "We can read the newly saved image subset and confirm the size is what we expect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a2c420-3393-4e9d-bfba-1bee3df782c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nir = rioxarray.open_rasterio(\"nir_subset.tif\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a454f2db-8859-4558-a406-f958cf6bfa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nir.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55194b5a-9aac-421e-8974-1646b70830ba",
   "metadata": {},
   "source": [
    "## Working with Raster Data\n",
    "\n",
    "This section introduces key concepts, tools, and attributes related to raster data in Python. It also covers strategies for managing missing or invalid values in raster datasets.\n",
    "\n",
    "We’ll use the `rioxarray` library as our main tool for raster processing. Built on `rasterio` (a library for working with raster files) and `xarray` (designed for multi-dimensional arrays), `rioxarray` enhances these tools by providing additional geospatial functionality. For example, it includes the `open_rasterio` function for reading raster files and extends `xarray` objects, such as `Dataset` and `DataArray`, with geospatial methods via the `rio` accessor. These features become available once you import `rioxarray`.\n",
    "\n",
    "To demonstrate, we will use the `nir09` band from the first image scene retrieved. This can be loaded with the `rioxarray.open_rasterio()` function, using the URL (Hypertext Reference or `href`) of the band asset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a83d32-5bbf-4246-93d6-eb10f91715e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9 = rioxarray.open_rasterio(s2_items[0].assets[\"nir09\"].href)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b002d3d-5ab4-4dd9-af3e-778d4610c885",
   "metadata": {},
   "source": [
    "We can quickly inspect the shape and attributes of the newly opened `nir09` dataset we titled `raster_b9` by printing the variable name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6190f779-3d99-4f14-baf3-5144d7d004fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0238f2-077e-4254-b8e3-dd65060c506d",
   "metadata": {},
   "source": [
    "When `rioxarray.open_rasterio()` is called, it retrieves the raster data from either local or remote storage and returns an `xarray.DataArray`. This object is assigned to a variable, such as `raster_b9`. While `xarray` itself also returns a `DataArray`, it doesn't include essential geospatial metadata like scene geometry or projection details. Without `rioxarray`, you can use `NumPy` functions or Python's math operations on a `DataArray` as you would with a `NumPy` array, but you won’t have access to the geospatial information.\n",
    "\n",
    "The output of the `DataArray` includes the variable name, along with details such as the number of bands (1), width in pixels (1830), and height in pixels (1830), as well as the pixel data type (e.g., unsigned integer `uint16`).\n",
    "\n",
    "Thanks to `rioxarray`, the `DataArray` also includes spatial coordinates (x and y) and band information, each with its own data type—`float64` for spatial coordinates and `int64` for bands. Additionally, `rioxarray` allows us to access important geospatial attributes, such as the coordinate reference system (CRS) using `.rio.crs` and the bounding box using `.rio.bounds()`. Note that while most metadata can be accessed directly via attributes like `.rio.crs`, some methods, like `.rio.bounds()`, require parentheses to retrieve the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6ed3d0-eefe-4ce4-bcba-62e0d141a3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raster_b9.rio.crs)\n",
    "print(raster_b9.rio.nodata)\n",
    "print(raster_b9.rio.bounds())\n",
    "print(raster_b9.rio.width)\n",
    "print(raster_b9.rio.height)\n",
    "print(raster_b9.rio._manager.acquire().block_shapes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42907cee-99a4-44b5-9277-9489fa707861",
   "metadata": {},
   "source": [
    "The Coordinate Reference System for `raster_b9.rio.crs` is returned as `EPSG:32643`. The no-data value is set to `0`, and the bounding box corners of our raster are returned by the output of `.bounds()`. The height and width in number of pixels are returned from `.rio.height` and `.rio.width`, respectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da504b6-f619-4902-8f77-082830b9e22c",
   "metadata": {},
   "source": [
    "## Visualizing raster data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3affe57a-3702-4089-97be-049369019e74",
   "metadata": {},
   "source": [
    "We've reviewed the attributes of our raster. Now let's see the raw values of the array with `.values`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4643aaf0-d59c-44af-9ec9-f4bd9faac418",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee02e73-e1ef-4f1b-8e18-adff45b9e55b",
   "metadata": {},
   "source": [
    "Displaying this allows us to quickly examine the array values, typically by viewing the pixel values at the image's corners. Since the raster is loaded as a `DataArray` in Python, we can easily visualize it using `DataArray.plot()`, much like how we would plot a `pandas` `DataFrame`, with a single line of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd74d1ee-93a8-47a1-92e4-cec9b2fab46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33acadd5-be55-4ff8-ad80-417c3c895856",
   "metadata": {},
   "source": [
    "With `rioxarray`, plotting a raster becomes straightforward, with spatial coordinates automatically labeled along the x and y axes for clarity.\n",
    "\n",
    "The visualization depicts pixel values for the spectral band `nir09` over the selected area of interest. According to Sentinel-2 documentation, this band, with a central wavelength of 945 nm, is particularly sensitive to water vapor. It has a spatial resolution of 60 meters, which, while lower than some other bands, is ideal for quick analyses and demonstrations.\n",
    "\n",
    "It's worth noting that the `band=1` label in the image title refers to the order of bands within the `DataArray` and not specifically to the Sentinel-2 band asset `nir09`.\n",
    "\n",
    "The image reveals high reflectance values in cloudy pixels, while other areas show lower contrast, consistent with the band’s sensitivity to water vapor. To enhance color contrast and better interpret the data, you can use the `robust=True` option, which restricts the display range to the 2nd and 98th percentiles of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd53cfa8-50d5-46c0-9454-a3a973e8f762",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9.plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea68def5-b80f-4178-89e8-d4b6dd77ea92",
   "metadata": {},
   "source": [
    "This functionality lets you adjust the color limits to better reflect the majority of pixel values in the image. \n",
    "\n",
    "If the `robust=True` option doesn't provide a satisfactory representation, you can further refine the visualization by manually setting the `vmin` and `vmax` parameters. In some cases, defining a value range may produce a more tailored plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d79f95b-6ea8-4e0c-a846-e924c4ad1f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9.plot(vmin=100, vmax=7000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb4f0c-f452-4563-9b79-649f0893363b",
   "metadata": {},
   "source": [
    "Now, if we want to plot a subset of this image to focus more on a specific feature of interest, we can select a region of pixels again. Let's look at the internal tiling for this band of the COG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad503f7-75df-4eda-8f03-2f3a7833aca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raster_b9.shape)\n",
    "tile_size = raster_b9.rio._manager.acquire().block_shapes\n",
    "tile_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ec102-58c9-43e7-83ca-a08ec1f3fad8",
   "metadata": {},
   "source": [
    "Notice that the tile size is smaller because the resolution for this band (`nir09`) is lower (60 meters) than that of the `nir` (10 meters). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee815a2a-a39c-4417-b146-8580c89bf95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the center coordinates of the image\n",
    "center_x, center_y = raster_b9.sizes[\"x\"] // 2, raster_b9.sizes[\"y\"] // 2\n",
    "\n",
    "# Select a crop region using .isel()\n",
    "raster_b9_subset = raster_b9.isel(\n",
    "    x=slice(center_x - tile_size[0][0]*3, center_x + tile_size[0][0]),\n",
    "    y=slice(center_y - tile_size[0][0]*2, center_y + tile_size[0][0]*2)\n",
    ")\n",
    "\n",
    "print(raster_b9_subset.shape)\n",
    "\n",
    "raster_b9_subset.plot(robust=True)\n",
    "plt.title(\"Crop of Sentinel-2 COG (NIR)\")\n",
    "plt.xlabel(\"X Pixel\")\n",
    "plt.ylabel(\"Y Pixel\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2441cb95-36ef-4c7c-979f-ab1531337219",
   "metadata": {},
   "source": [
    "## Deciphering the Raster Coordinate Reference System (CRS)\n",
    "\n",
    "An essential detail to examine in geospatial data is the Coordinate Reference System (CRS), which defines how spatial data is mapped to the Earth’s surface. Using the `.rio.crs` method, you can access the CRS information of your dataset. This method retrieves the CRS string associated with your `DataArray`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c3d43d-3a00-4cc9-a086-5774a2f99b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raster_b9.rio.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1595a703-351a-43ff-9a58-489e83d24c78",
   "metadata": {},
   "source": [
    "EPSG codes are a standardized and concise way to identify specific Coordinate Reference Systems (CRS). To explore detailed information about a CRS, such as its unit of measurement, the `pyproj` library can be used. This library is designed to manage and perform operations related to CRS definitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d8f553-e990-498b-bb19-7d726edba3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg = raster_b9.rio.crs.to_epsg()\n",
    "crs = CRS(epsg)\n",
    "crs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb889a7b-a52f-4d27-82b3-a8090a885c0d",
   "metadata": {},
   "source": [
    "The ``CRS`` class from the ``pyproj`` library enables us to create a CRS object. We can retrieve specific information about a CRS from this, as well as obtain a basic summarization of the associated CRS.\n",
    "\n",
    "One especially valuable attribute is ``area_of_use``, which indicates the geographic boundaries for which the CRS is designed to be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da3dfcc-3a3c-40dd-b4d9-b0738b60c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "crs.area_of_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3c02135-495d-4910-bfb3-51eb00157fb3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# More on the various attributes accessible for the CRS class can be viewed with the following:\n",
    "# help(crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf88d92-437d-4b24-a205-f1189b059170",
   "metadata": {},
   "source": [
    "The `pyproj` CRS summary outlines all the details of a Coordinate Reference System (CRS) that Python or GIS software may utilize. For example, it describes the projection as **UTM Zone 43N**, part of the Universal Transverse Mercator (UTM) system, which divides the globe into 60 zones, each covering 6 degrees of longitude. \n",
    "\n",
    "This specific CRS uses the **WGS84 datum** as its reference point and applies a Cartesian coordinate system with two axes: `easting` and `northing`, measured in meters. Its geographic range spans from **72°E to 78°E** longitude and **0.0°N to 84.0°N** latitude in the northern hemisphere. \n",
    "\n",
    "The **Transverse Mercator** projection method is employed, optimal for regions with narrow longitudinal widths, such as UTM zones. Additionally, the CRS attributes include the mechanism for projecting coordinates onto a flat (Cartesian) plane. While the UTM system includes zones, not all CRSs are zone-specific, and this detail pertains specifically to UTM-based systems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae5d177-780e-4d64-ab12-1758988fabec",
   "metadata": {},
   "source": [
    "## Calculate Raster Statistics\n",
    "Knowing basic statistical values of a raster dataset can be valuable. We can obtain some, such as minimum, maximum, mean, and standard deviation quite easily for `xarray.DataArray`s like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be3b251-6e29-4f4f-8e87-41356af8d4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raster_b9.min())\n",
    "print(raster_b9.max())\n",
    "print(raster_b9.mean())\n",
    "print(raster_b9.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578b7706-0ba4-44e7-a95a-29e7598f9514",
   "metadata": {},
   "source": [
    "So with that, we can get key statistical values such as the minimum, maximum, mean, and standard deviation, along with the data type of the pixels. However, if you're interested in calculating specific quantiles, `xarray` provides the `.quantile()` method. For example, to determine the 25th and 75th percentiles, you can try the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a937fc-897f-4dc9-9834-3dcdcf36bfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raster_b9.quantile([0.25, 0.75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5d9705-eb65-4d86-9176-bd527791078f",
   "metadata": {},
   "source": [
    "## Dealing with Missing Data\n",
    "\n",
    "So far, we've visualized a band from a Sentinel-2 image and calculated its statistics. However, it's critical to account for missing data, often indicated by a \"nodata\" value in raster datasets. This special value represents pixels where no valid data is available, typically due to sensor limitations or incomplete coverage. Missing data frequently appears along the raster's edges when the dataset doesn't fully cover the analyzed region.\n",
    "\n",
    "Raster datasets inherently have a rectangular structure, so areas without data—such as boundaries not covered by the sensor—are assigned the nodata value. For example, in this dataset, the nodata value (`raster_b9.rio.nodata`) is **0**. When visualizing the data or calculating statistics, these missing values can be mistakenly treated as valid, leading to skewed results. For instance, including nodata pixels with a value of zero could lower the 25th percentile or other metrics inaccurately.\n",
    "\n",
    "To handle this, missing data can be represented as `NaN` (Not a Number), which ensures it is excluded from calculations. This transformation can be achieved by setting the parameter `masked=True` when loading the raster dataset. This approach provides a clearer distinction between valid and missing data, preventing distortion in analyses or visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc1f709-f20a-401e-a385-813012b6b11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9 = rioxarray.open_rasterio(s2_items[0].assets[\"nir09\"].href, masked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59901deb-815b-4d30-800e-77750c143d36",
   "metadata": {},
   "source": [
    "You can also utilize the `where` function to filter out all the pixels that differ from the raster's `nodata` value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c4aa33-2175-4f8f-805f-9e3d509e89d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_b9.where(raster_b9!=raster_b9.rio.nodata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a59735-80ef-48e9-aa4b-e61a6ba9e0ac",
   "metadata": {},
   "source": [
    "Both approaches will replace the nodata value of **0** with `NaN`, allowing missing data to be excluded from calculations. This ensures that recalculated statistics are accurate, as the nodata pixels are no longer treated as valid data points. \n",
    "\n",
    "By the way, a tip for a cleaner output: you can use the `.values` attribute when applying statistical functions. This returns only the computed values, without including any of the object metadata associated with the raster dataset. This streamlined result is particularly useful for further numerical analysis or visualization, as it provides just the values without the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd43995-0ef4-4d1b-9156-d3c7b0613072",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(raster_b9.min().values)\n",
    "print(raster_b9.max().values)\n",
    "print(raster_b9.mean().values)\n",
    "print(raster_b9.std().values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37eb14-61b3-41f9-a032-d5036b0a9ae8",
   "metadata": {},
   "source": [
    "It's worth mentioning that replacing `0` with `nan` to represent missing data will cause a change in the data type of the `DataArray` from integers to floats. This is an important consideration if the data type plays a crucial role in your specific use case or application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35426286-7ae8-4d71-8d11-d50d84572332",
   "metadata": {},
   "source": [
    "## Incorporating multiple bands \n",
    "\n",
    "Up to now, we have worked with single-band rasters, focusing on the `nir` and later the `nir09` bands from a Sentinel-2 scene. To obtain a more easy-to-interpret RGB \"true-color\" depiction of the area, we can utilize the True Color Image (TCI) asset. This asset provides a high-resolution visualization by combining three optical bands—Red, Green, and Blue (RGB)—captured by the Sentinel-2 satellite’s MultiSpectral Instrument (MSI). With a spatial resolution of 10 meters, the TCI functions as a clear and detailed view of the area, making it ideal for quick visual assessments and analysis. Like the `nir09` band, we can load the TCI using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6632bf17-2ca5-4b05-93c0-cb3e50b66d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_overview = rioxarray.open_rasterio(s2_items[0].assets['visual'].href, overview_level=3)\n",
    "raster_overview"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0061d55-3d89-4e5c-9554-82bea618b3a2",
   "metadata": {},
   "source": [
    "We specified the argument `overview_level=3`, which corresponds to the spatial resolution determined by the level of downsampling in Sentinel-2 COGs. The native spatial resolution for Sentinel-2's True Color Image (TCI) bands is 10 meters. However, each overview level reduces this resolution by a factor of 2.\n",
    "\n",
    "The resolution at different overview levels is as follows:\n",
    "- Level 0 (native): 10 meters\n",
    "- Level 1: 20 meters\n",
    "- Level 2: 40 meters\n",
    "- Level 3: 80 meters\n",
    "\n",
    "When loading GeoTIFFs with the `open_rasterio()` function and checking the shape, the band dimension will appear first. For instance, in the `xarray.DataArray` object, the shape would be `(band: 3, y: 687, x: 687)`, showing three bands. It's always a good idea to inspect the shape of the raster array both after loading it and during any data manipulations (such as calculating band ratios or warping). This is especially important since many functions, particularly those for image plotting, expect the raster to have a specific shape (e.g., 1 or 3 channels arranged in a certain order). You can easily verify the shape using the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f852c603-ef5f-4441-8801-732fd5410bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_overview.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f3c419-674b-4a47-b4ce-beaff218a164",
   "metadata": {},
   "source": [
    "You can visualize the multi-band data using the `DataArray.plot.imshow()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f011c16b-9d01-45f5-8b27-9f54acd1f250",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_overview.plot.imshow()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dc0d1df-c7ec-4d97-85d3-b988097020b8",
   "metadata": {},
   "source": [
    "Keep in mind that the `DataArray.plot.imshow()` function is designed to work with image arrays that have three channels, which corresponds to the RGB color model. It is not suitable for arrays containing more than three channels. However, you can create a false-color image by using different channels in place of the typical RGB.\n",
    "\n",
    "As shown in the previous figure, the true-color image may appear stretched. To correct the aspect ratio, you can adjust the settings in `DataArray.plot.imshow()`. Since the height-to-width ratio is 1:1 (verified by the `rio.height` and `rio.width` attributes), it's best to set the aspect ratio to 1. For example, you might choose to set the plot size to 5 inches and specify `aspect=1`. Keep in mind that when using the `aspect` argument, you must also define the plot size, as indicated in the `DataArray.plot.imshow()` documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b46e87-8215-41fc-9417-3e0b5501ee16",
   "metadata": {},
   "outputs": [],
   "source": [
    "raster_overview.plot.imshow(size=5, aspect=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb98a609-9360-46d6-80e8-1b85f5b83920",
   "metadata": {},
   "source": [
    "Now, let's consider working not only with visual bands but also with other bands like the `nir` band. We'll introduce a new tool called [Open Data Cube (ODC)](https://www.opendatacube.org/), which we imported as `odc`, to help load multi-spectral time series raster data from STAC into an `xarray.Dataset`. The `odc` library provides an extension for handling raster data from STAC-compliant catalogs. We'll use this to more efficiently manage the Sentinel-2 data we previously queried.\n",
    "\n",
    "In the following cell, the process is as follows:\n",
    "\n",
    "1. **`s2_data = odc.stac.load(...)`**:\n",
    "   - This loads the actual raster data from the Sentinel-2 items we retrieved earlier. The `load` function from `odc` fetches the data associated with the metadata.\n",
    "\n",
    "2. **`items=s2_items`**:\n",
    "   - Here, `s2_items` represents the Sentinel-2 scenes we collected from the STAC catalog, which contain the metadata and location information.\n",
    "\n",
    "3. **`bands=[\"red\", \"green\", \"blue\", \"nir\", \"scl\"]`**:\n",
    "   - This specifies the spectral bands to load, including Red, Green, Blue, Near-Infrared (NIR), and the Scene Classification Layer (SCL), which helps identify cloudy pixels.\n",
    "\n",
    "4. **`bbox=box_coords`**:\n",
    "   - The `bbox` argument defines the **Area of Interest (AOI)** by specifying the geographic bounding box using coordinates in the format `[min_longitude, min_latitude, max_longitude, max_latitude]`, which corresponds to the region we are interested in.\n",
    "\n",
    "5. **`progress=tqdm`**:\n",
    "   - The `progress` argument integrates `tqdm`, a library that shows a progress bar, helping track the loading process, especially when dealing with large datasets.\n",
    "\n",
    "**IMPORTANT:**\n",
    "When the `bbox` argument is provided, `odc` will automatically clip the raster data to match the bounding box. This ensures that only the relevant data for the specified region is returned.\n",
    "\n",
    "The resulting `s2_data` is an `xarray.Dataset` that we can use for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c727769a-efe2-4c86-98af-0de8657472c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data = odc.stac.load(\n",
    "    items=s2_items[:12],\n",
    "    bands=[\"red\", \"green\", \"blue\", \"nir\", \"scl\"],\n",
    "    bbox=bbox_coords,\n",
    "    progress=tqdm,\n",
    "    chunks={'x': 1024, 'y': 1024, 'time': -1},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77655535-b292-4c93-8607-f2228f046038",
   "metadata": {},
   "source": [
    "The `odc.stac.load()` function returns an `xarray.Dataset` instead of an `xarray.DataArray` because we are loading multiple spectral bands (e.g., \"red\", \"green\", \"blue\", \"nir\", \"scl\"). An `xarray.Dataset` is used to store multiple variables, or bands, each represented as a `DataArray`. A `DataArray` typically holds a single variable (e.g. band) along with its associated dimensions and coordinates. Since we are loading more than one band, the function returns a `Dataset`, which is essentially a collection of `DataArrays`, each corresponding to one of the requested bands.\n",
    "\n",
    "The `xarray.Dataset` structure allows you to work with related variables (e.g., spectral bands) that share common coordinates, such as latitude, longitude, and time. This structure is particularly useful when performing operations that involve multiple bands, like creating a composite RGB image or conducting multi-band analyses. \n",
    "\n",
    "If you were only loading a single band, the function would return a `DataArray`, which is more suited to handling one variable. However, since multiple bands are requested, a `Dataset` is the appropriate return type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4815bb-c18a-43cb-8d5b-55e3765010d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7380a5c-47cf-4bed-9829-09577cca4a8a",
   "metadata": {},
   "source": [
    "Notice that the time dimension is automatically interpreted and aligned with the number of items returned from `s2_search.matched()` and `len(s2_items)` earlier. This means that the dataset now contains multiple Sentinel-2 images, each corresponding to different timestamps and overlapping the area of interest (AOI). By default, `odc` stacks these images in a time series, without assuming any manipulation is required on the time dimension.\n",
    "\n",
    "To visualize the dataset, we can composite the images over time, reducing the temporal dimension to a single layer where each pixel represents the average of all available timestamps. This approach gives us a temporal depth of 1, providing a composite that reflects changes over time, simplifying the data for easier interpretation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7c12c7-135f-47b5-8a7c-45ab26f86721",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data_composite = s2_data.mean(dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386629f5-c5b8-4440-850c-0cd23f913536",
   "metadata": {},
   "source": [
    "Notice the new shape of the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f43eb-7c72-43b3-9d56-b4a1187d4b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data_composite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0e1311-a503-4a05-b152-d02ce4880500",
   "metadata": {},
   "source": [
    "Also notice here that the aspect ratio is not perfectly 1:1, so let's compute the correct aspect ratio to use when plotting. We can plot a true color image from the dataset by specifying the necessary bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34df638f-b548-461e-9bd6-b7d406559052",
   "metadata": {},
   "outputs": [],
   "source": [
    "aspect_ratio_composite = s2_data_composite.x.shape[0] / s2_data_composite.y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ec48e22-d9ef-40dc-b707-377ce5fd98b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data_composite[[\"red\", \"green\", \"blue\"]].to_array(\"band\").plot.imshow(rgb=\"band\", robust=True, size=5, aspect=aspect_ratio_composite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0102314c-ce43-47db-9975-6f749d9e59c8",
   "metadata": {},
   "source": [
    "We can also plot any single band from the dataset like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9890ed-4130-4fbe-8436-1b5778d76d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data_composite[[\"nir\"]].to_array(\"band\").plot(robust=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098a347e-587d-4b88-adbe-67795eb1a6a3",
   "metadata": {},
   "source": [
    "Let's say we want to take a look at the time series for a single band. We can do this by taking the average in the spatial dimensions (x and y) for each timestamp and plotting the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed1cbe-c7e9-4bcd-b0a1-ac29d2d169cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data_mean_time_series = s2_data.mean(dim=[\"y\", \"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7d76f-d2cc-47dd-b652-d02acd72c783",
   "metadata": {},
   "source": [
    "Then we can extract the time series for one of bands. Near infrared is interesting because it is useful in determing seasonal phenology."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1d0687-6f3c-4364-9b14-4da1d895bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nir_time_series = s2_data_mean_time_series[\"nir\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5774fb4-daf7-44f1-9c42-66cb545fbf42",
   "metadata": {},
   "source": [
    "We can plot a line plot for the near infrared averages for each timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fe5da1-7b7b-420f-be7a-37bcb8b6d482",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "nir_time_series.plot(label='Near Infrared Band', marker='o')\n",
    "\n",
    "plt.title(\"Time Series of Mean Near Infrared Band Values\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c040a8f3-5d65-49c4-ac1f-e8cbe188d507",
   "metadata": {},
   "source": [
    "## Dealing with cloud-covered and invalid pixels\n",
    "\n",
    "To mask out clouds and invalid pixels from Sentinel-2 data, we can use the 'SCL' (Scene Classification Layer) band, which includes cloud and no data information. The SCL band classifies each pixel in the Sentinel-2 image, including cloud-related classes such as cloud shadows, medium-probability clouds, high-probability clouds, and cirrus clouds. By masking out these classes as well as those with the no data value, we can ignore unwanted pixels in the dataset.\n",
    "\n",
    "First we need to declare the cloud-related SCL classes. The common classes for clouds are:\n",
    "\n",
    "> Cloud Shadows: 3\n",
    ">\n",
    "> Low probability clouds: 7\n",
    ">\n",
    "> Medium probability clouds: 8\n",
    "> \n",
    "> High probability clouds: 9\n",
    "> \n",
    "> Thin cirrus: 10\n",
    "\n",
    "In order to mask out these cloud classes, we'll create a boolean mask using `xarray`'s `.isin()` method. We will use these masks to filter out cloud-covered and invalid pixels in the red, green, blue, and NIR bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadfbb20-ef51-40e0-94bc-40ff154a0f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_classes = [3, 7, 8, 9, 10]  # Cloud-related SCL classes\n",
    "cloud_mask = s2_data['scl'].isin(cloud_classes)\n",
    "masked_s2_data = s2_data[['red', 'green', 'blue', 'nir']].where(~cloud_mask, drop=False)  # Keep all pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10512de-5890-41a1-845d-1196f7d8d949",
   "metadata": {},
   "source": [
    "We will do the same for the no data \"class.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2feb499e-f30a-40f3-b2ee-bd08b2999df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata_value =  s2_data['scl'].nodata\n",
    "nodata_mask = s2_data['scl'].isin(nodata_value)\n",
    "masked_s2_data = masked_s2_data[['red', 'green', 'blue', 'nir']].where(~nodata_value, drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b578a-574a-4190-9979-cffd1b8ddec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6dbf87-e9d1-4094-bdcc-587eb0d1fdac",
   "metadata": {},
   "source": [
    "Let's examine the masked data to verify the results. To do this, let's composite the imagery again to get a temporal average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411cf87f-333f-4572-8f40-5724ec7d99c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_data_composite = masked_s2_data.mean(dim='time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd62fb2b-4aa7-4ffd-bbfd-98873d0a4161",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_data_composite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04965202-98a9-4cf5-a40e-81fffe6f24ef",
   "metadata": {},
   "source": [
    "Now we can plot an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274ea664-9576-44f9-81fe-30c898e950b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_data_composite[['red', 'green', 'blue']].to_array(\"band\").plot.imshow(rgb=\"band\", robust=True, size=5, aspect=aspect_ratio_composite)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc85ee2-25bc-4345-8c7c-9b420c45b920",
   "metadata": {},
   "source": [
    "The image plot is looking a bit over-exposed. Let's adjust the value ranges to better fit the raster data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871781f5-9084-4bc7-afd7-5f49a636ee33",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_data_composite[['red', 'green', 'blue']].to_array(\"band\").plot.imshow(rgb=\"band\", robust=True, size=5, aspect=aspect_ratio_composite, vmin=0, vmax=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881fe9fe-91c5-4423-ad54-7ae31fa6586e",
   "metadata": {},
   "source": [
    "That looks pretty good! Now we have a cloud-masked composite. We can use this to get a clearer signal of near infrared over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752c82d1-b30a-4e71-9ffe-80edc721695a",
   "metadata": {},
   "source": [
    "## Calculate a spectral index\n",
    "\n",
    "In this next section, we will use our masked multi-spectral data to calculate a relevant spectral index for tasks such as crop type classification.\n",
    "\n",
    "**NDVI (Normalized Difference Vegetation Index)** is a widely used index to assess vegetation health and density. It quantifies the difference between near-infrared (NIR) light, which vegetation strongly reflects, and red light, which vegetation absorbs. Higher NDVI values typically indicate healthier or denser vegetation, while lower or negative values suggest sparse or no vegetation (e.g., bare soil, urban areas, or water)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dfd051-8670-4387-9fc5-28fbb0e89d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_ndvi = (masked_s2_data[\"nir\"] - masked_s2_data[\"red\"]) / (masked_s2_data[\"nir\"] + masked_s2_data[\"red\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b6fb41-5ddb-4c05-9dcc-3eed28579870",
   "metadata": {},
   "source": [
    "Now let's make a time series again and plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8558e3-05c7-4efd-a738-f58c87edae0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_ndvi_mean_time_series = masked_s2_ndvi.mean(dim=[\"y\", \"x\"])\n",
    "plt.figure(figsize=(10, 6))\n",
    "masked_s2_ndvi_mean_time_series.plot(label='NDVI', marker='o')\n",
    "\n",
    "plt.title(\"Time Series of Mean NDVI Values\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.ylabel(\"Mean Value\")\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed773e6-eb32-451f-9dd5-bf4954930018",
   "metadata": {},
   "source": [
    "The dataset titled **\"10,000 Crop Field Boundaries across India\"** (by Wang et al., 2022) contains manually delineated boundaries of 10,000 crop fields across India, created through the analysis of high-resolution satellite imagery from Airbus SPOT. The dataset is specifically designed to support research and applications in crop field mapping and agricultural monitoring, particularly in smallholder farming systems.\n",
    "\n",
    "This dataset aims to advance methods for identifying and analyzing crop fields at scale, enabling better understanding and management of smallholder farming landscapes. For further details and access to the dataset and model weights, visit the [Zenodo record](https://zenodo.org/record/7315090).\n",
    "\n",
    "We will use this dataset to demonstrate scalably vector dataset visualization with Lonboard and then subsquently compute zonal statistics using the polygons, our subdistrict and a NDVI raster.\n",
    "\n",
    "Let's start by reading in the shapefile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10460828-05f0-4b24-9536-b14c00ce1da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_boundaries_india = gpd.read_file(\"./7315090/india_10k_fields.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad3a8a5-05a1-4896-ad0d-315eea0c1122",
   "metadata": {},
   "outputs": [],
   "source": [
    "field_boundaries_india"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c14552a-1472-444b-999c-40a2ff30835f",
   "metadata": {},
   "source": [
    "And then visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff84777-982c-45f9-b2f2-0d398a15df3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = PolygonLayer.from_geopandas(\n",
    "    field_boundaries_india,\n",
    "    get_line_width=20,  # width in default units (meters)\n",
    "    line_width_min_pixels=0.2,  # minimum width when zoomed out\n",
    "    get_fill_color=[255, 0, 0],  # red\n",
    "    get_line_color=[37, 36, 34],  # dark border color\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a24b0-fa40-4d91-8148-6bb899318c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Map(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226862ad-6431-45f5-bbeb-d063d77beba0",
   "metadata": {},
   "source": [
    "Now let's get all of the field boundaries within the subdistrict we've been focusing on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a86b149-4f90-4230-b10b-417c43d7a66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_field_boundaries_india = field_boundaries_india.to_crs(epsg=4326).clip(scene_geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b33f466-d3bf-4a8d-b2d0-3dc3b6a80415",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(clipped_field_boundaries_india)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18dd5965-ec2d-44b4-afe9-c03751b04786",
   "metadata": {},
   "source": [
    "Let's visualize the clipped results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3cc3fe-8814-4ae2-a8f3-d199248a45ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer = PolygonLayer.from_geopandas(\n",
    "    clipped_field_boundaries_india,\n",
    "    get_line_width=20,  # width in default units (meters)\n",
    "    line_width_min_pixels=0.2,  # minimum width when zoomed out\n",
    "    get_fill_color=[255, 0, 0],  # red\n",
    "    get_line_color=[37, 36, 34],  # dark border color\n",
    ")\n",
    "\n",
    "m = Map(layer)\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c310478-47f6-45da-bc41-311483cab8e7",
   "metadata": {},
   "source": [
    "Now, let's just take one field boundary to compute zonal statistics for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be44589-e92d-4bd7-a739-6c7d6c67e099",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_field_boundaries_india_single = clipped_field_boundaries_india.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13e8d737-26e7-49e6-8a8a-98b9e11d388c",
   "metadata": {},
   "outputs": [],
   "source": [
    "viz(clipped_field_boundaries_india_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8ae50-99a6-4ee4-99bb-af15237eefbd",
   "metadata": {},
   "source": [
    "Get the raster data for the bounds of this polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce7cc09-4ba4-42aa-86a2-7b9b1cbfd098",
   "metadata": {},
   "outputs": [],
   "source": [
    "s2_data = odc.stac.load(\n",
    "    items=s2_items,\n",
    "    bands=[\"red\", \"green\", \"blue\", \"nir\", \"scl\"],\n",
    "    bbox=clipped_field_boundaries_india_single.total_bounds,\n",
    "    progress=tqdm,\n",
    "    epsg=4326,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfbc21f-a285-4363-9aa4-04cb92037c5f",
   "metadata": {},
   "source": [
    "Get the cloud and no data masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e4086c-7922-4001-a3f4-690ce1fe89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloud_mask = s2_data['scl'].isin(cloud_classes)\n",
    "nodata_value =  s2_data['scl'].nodata\n",
    "nodata_mask = s2_data['scl'].isin(nodata_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "630aa687-ff52-46a8-af91-9fb4c38601b6",
   "metadata": {},
   "source": [
    "Mask the non-SCL bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20bb73c2-4d36-4795-a4df-64fd99aeb056",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodata_masked_s2_data = s2_data[['red', 'green', 'blue', 'nir']].where(~nodata_value, drop=False)  # Keep all pixels\n",
    "cloud_masked_s2_data = nodata_masked_s2_data[['red', 'green', 'blue', 'nir']].where(~cloud_mask, drop=False)  # Keep all pixels\n",
    "masked_s2_data = cloud_masked_s2_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f50cda1e-5acc-4eac-a880-14739b0a2513",
   "metadata": {},
   "source": [
    "Calculate NDVI for this new Sentinel-2 raster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc06745-c271-4d92-946b-2a508e44af46",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_ndvi = (masked_s2_data[\"nir\"] - masked_s2_data[\"red\"]) / (masked_s2_data[\"nir\"] + masked_s2_data[\"red\"])\n",
    "\n",
    "masked_s2_ndvi_composite = masked_s2_ndvi.mean(dim=[\"time\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d52c9-59c8-4bf0-b121-7aa379f44bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_s2_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3ebe1-3b77-48e5-bd65-33e1364f7d45",
   "metadata": {},
   "source": [
    "Now let's calculate zome basic statistics for NDVI within this field boundary polgon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64771337-bef4-47be-a965-a17e0a408648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate zonal stats\n",
    "stats = zonal_stats(\n",
    "    clipped_field_boundaries_india_single.to_crs(epsg=32643), #clipped_field_boundaries_india.to_crs(epsg=32643),\n",
    "    masked_s2_ndvi_composite.values,\n",
    "    affine=masked_s2_ndvi_composite.rio.transform(),\n",
    "    stats=[\"mean\", \"min\", \"max\", \"sum\"],\n",
    "    geojson_out=True\n",
    ")\n",
    "\n",
    "# Convert the results back to a GeoDataFrame\n",
    "zonal_stats_gdf = gpd.GeoDataFrame.from_features(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42446cc4-4839-4858-b0ed-ace280f3d0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "zonal_stats_gdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
